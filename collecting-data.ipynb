{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting my twitter likes\n",
    "\n",
    "I entered Twitter because of the network of researchers and programmers that posts there. Because of that, I also have been doing 'favs' quite selectively, with an occasional like on some anime or cat or political tweet. As a \"data scientist\" (I almost choked saying that) I want to cluster the favorite tweets based on the text presented in these tweets - I reckon that it could be necessary to scrap the content that some of these tweets link to, but I am keeping it simple because I only faved what met the eye to be honest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the twitter api\n",
    "\n",
    "The first step is to go to the 'developers' section on twitter and create an app for personal use. This is to obtain the credentials to connect to the api - it's kind of like username/password but slightly more complicated. Instead of coding http requests from scratch, we are going to use an open source api wrapper, found on [bear/python-twitter](https://github.com/bear/python-twitter). After following the installation you can import the module as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter # has to be installed with 'pip install python-twitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys # so as to know the error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My API credentials are not explicit here, as this is in the open web. Note that there is a running joke that you can find free api keys on github (for services that are paid!). This is a read-in from a `.gitignore`d file, but you can imagine that these api keys look like something your cat would type on the keyboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('creds.pkl', 'rb') as handle:\n",
    "    creds = pickle.load(handle)\n",
    "\n",
    "# connect to the twitter api with your twitter app credentials\n",
    "api = twitter.Api(consumer_key = creds['consumer_key'],\\\n",
    "                  consumer_secret = creds['consumer_secret'],\\\n",
    "                  access_token_key = creds['access_token_key'],\\\n",
    "                  access_token_secret = creds['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with this last call, we are connected to the api that wraps our http requests into functions :). I can then proceed to fetch some data. After sifting through some of the documentation of the api wrapper, I found what I wanted: the [`GetFavorites()`](https://python-twitter.readthedocs.io/en/latest/twitter.html#twitter.api.Api.GetFavorites) method that wraps the http request to the corresponding [endpoint](https://developer.twitter.com/en/docs/tweets/post-and-engage/api-reference/get-favorites-list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recent_favs = api.GetFavorites(screen_name='burnie093', count = 200) # this is a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Steps to better code\\n{ author: @isaacandsuch }\\nhttps://t.co/lHL37fyC8e'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_favs[0].AsDict() # recent_favs[*] is a twitter.models.Status with a method AsDict()\n",
    "recent_favs[0].AsDict()['text'] # you can now access the dict element text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the texts to a file\n",
    "\n",
    "Part of the drill is to save data to files to later read it back in. And note, we only have the most recent 200 tweets, and we want to get all of the ~900 favorited tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formats\n",
    "Ok here are possible formats to save the file\n",
    "- `json` (\"JavaScript Object Notation\"), this is a stringified version of the notation every js object uses and can be seen as correspondent to the python dict. Just a mention so that you know what this means when reading other documentation.\n",
    "- plain text or csv, need I say more? It's a classic one and often used as well. But I want to leverage a python/c feature so I'll go with the next\n",
    "- **`pickle`** this is a serialization mechanism to save a **python object** such as the list we currently have stored in the variable `texts`. Unlike the other two formats, this reads in the data as a python object, saving me from dealing with type conversion. [Here](https://stackoverflow.com/a/11218504)'s how to use it.\n",
    "\n",
    "And for future reference for beginners, a file is just really a file which is not determined by its extension, only by its content. Extensions are just conventions among us computer people. If you want to give some wings to your evil genius, you could write a python program and save it with a java extension, e.g. `definitely_not_python.java`, and the fact is, the command `python definitely_not_python.java` (executing the python program) would work because the syntax would be parsed as python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_save = [recent_favs[i].AsDict() for i in range(len(recent_favs))] # I changed my mind\n",
    "with open('data/favs_0.pkl', 'wb') as handle: # 'wb' stands for 'write binary'\n",
    "    pickle.dump(to_save, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read it back in again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = []\n",
    "for i in range(5):\n",
    "    with open('data/favs_%d.pkl' % i, 'rb') as handle:\n",
    "        batches.append(pickle.load(handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Sat Sep 30 08:02:01 +0000 2017',\n",
       " 'favorite_count': 62,\n",
       " 'favorited': True,\n",
       " 'hashtags': [],\n",
       " 'id': 914037602378010624,\n",
       " 'id_str': '914037602378010624',\n",
       " 'lang': 'en',\n",
       " 'retweet_count': 18,\n",
       " 'source': '<a href=\"http://bufferapp.com\" rel=\"nofollow\">Buffer</a>',\n",
       " 'text': 'Steps to better code\\n{ author: @isaacandsuch }\\nhttps://t.co/lHL37fyC8e',\n",
       " 'urls': [{'expanded_url': 'https://dev.to/isaacandsuch/steps-to-better-code',\n",
       "   'url': 'https://t.co/lHL37fyC8e'}],\n",
       " 'user': {'created_at': 'Fri Aug 15 19:11:17 +0000 2014',\n",
       "  'description': 'Coding resources, commentary and community. Helping you become a better developer maybe. Created by @bendhalpern',\n",
       "  'favourites_count': 40814,\n",
       "  'followers_count': 128115,\n",
       "  'following': True,\n",
       "  'friends_count': 2253,\n",
       "  'id': 2735246778,\n",
       "  'lang': 'en',\n",
       "  'listed_count': 2658,\n",
       "  'name': 'The Practical Dev',\n",
       "  'profile_background_color': '131516',\n",
       "  'profile_background_image_url': 'http://pbs.twimg.com/profile_background_images/601385812760993793/2pxLSwZZ.jpg',\n",
       "  'profile_background_tile': True,\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/2735246778/1492833420',\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/881896578633445376/j_dhfgoj_normal.jpg',\n",
       "  'profile_link_color': '14BD7B',\n",
       "  'profile_sidebar_fill_color': '000000',\n",
       "  'profile_text_color': '000000',\n",
       "  'screen_name': 'ThePracticalDev',\n",
       "  'statuses_count': 11386,\n",
       "  'time_zone': 'Pacific Time (US & Canada)',\n",
       "  'url': 'https://t.co/lhcCPP1ReQ',\n",
       "  'utc_offset': -25200},\n",
       " 'user_mentions': [{'id': 302340509,\n",
       "   'name': 'Isaac Lyman',\n",
       "   'screen_name': 'isaacandsuch'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[0][0]  # this is what an instance looks like... It's still json data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting all the faved tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there is a maximum count of the tweets you can retrieve from twitter: 200. So for each request, we can retrieve 200 tweets at a time. Let us collect the remaining ones, and for such we need to know the `max_id` to pass to the function. It should be at the last element..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "896645982854754304"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxi = hi[-1]['id']\n",
    "maxi # 896645982854754304"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loops the store of all my faved tweets so far, and because the list is finite, it will throw an error when it can't retrieve any more tweets. This doesn't need to be run anymore (only one time suffices) as the data is already stored in files `favs_0.pkl` through `favs_4.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxi = 896645982854754304\n",
    "for f in range(1,10): # will do this four more times, and will probably throw an error at some point\n",
    "    try:\n",
    "        favs = api.GetFavorites(screen_name='burnie093', count = 200, max_id = maxi)\n",
    "        to_save = [favs[i].AsDict() for i in range(len(favs))]\n",
    "        with open('favs_%d.pkl' % f, 'wb') as handle: # 'wb' stands for 'write binary'\n",
    "            pickle.dump(to_save, handle)\n",
    "        \n",
    "        # prepare for the next iteration\n",
    "        f += 1\n",
    "        if maxi == to_save[-1]['id']:\n",
    "            break\n",
    "        else:\n",
    "            maxi = to_save[-1]['id']\n",
    "    except:\n",
    "        print(sys.exc_info()[0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('favs_4.pkl', 'rb') as handle:\n",
    "    some = pickle.load(handle)\n",
    "len(some)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and extracting only text\n",
    "By the way, let me drop this thing on more [nested list comprehension](https://stackoverflow.com/a/8050243), as probably the following could have been one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "for i in range(5): # i belongs to [0, 5[\n",
    "    with open('data/favs_%d.pkl' % i, 'rb') as handle:\n",
    "        texts.extend([t['text'] for t in pickle.load(handle)])\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that corresponds to the same number of faved tweets on my twitter profile, except ahead of the website server by 2 faved tweets? ![](./data/faved.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of it, I will show some faved tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Steps to better code\\n{ author: @isaacandsuch }\\nhttps://t.co/lHL37fyC8e',\n",
       " 'I just published “Understanding your energy bill” https://t.co/Q2MutjiFjE',\n",
       " 'Yes I am making sure adequate cat photo benchmarks are in our talk and am currently comparing the performance of different cats',\n",
       " 'Coding = thinking in several dimensions\\n{ author: @andreasklinger }\\nhttps://t.co/3WHV4x6XEZ',\n",
       " \"@pewdiepie Kimi no na wa used heavily japanese ideas in the story that was pretty vital to the plot. Hollywood's go… https://t.co/OPFp64DLHg\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
